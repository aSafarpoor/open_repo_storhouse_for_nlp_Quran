{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW4_Practical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E54BrfHvj5yV"
      },
      "source": [
        "<div align=center>\n",
        "\t\t\n",
        "<p></p>\n",
        "<p></p>\n",
        "<font size=5>\n",
        "In the Name of God\n",
        "<font/>\n",
        "<p></p>\n",
        " <br/>\n",
        "    <br/>\n",
        "    <br/>\n",
        "<font color=#FF7500>\n",
        "Sharif University of Technology - Departmenet of Computer Engineering\n",
        "</font>\n",
        "<p></p>\n",
        "<font color=blue>\n",
        "Machine Learning - Dr. Hamid Beigy\n",
        "</font>\n",
        "<br/>\n",
        "<br/>\n",
        "Fall 2021\n",
        "\n",
        "</div>\n",
        "\n",
        "<hr/>\n",
        "\t\t<div align=center>\n",
        "\t\t    <font color=red size=6>\n",
        "\t\t\t    <br />\n",
        "Practical Assignment \n",
        "            \t<br/>\n",
        "\t\t\t</font>\n",
        "</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcX5m2hakwg_"
      },
      "source": [
        "Complete the Todo parts and just run the other cells. Do not add any additional cell to the notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M84mmCiHwHt"
      },
      "source": [
        "# Feature Extraction with Different Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTamZA0HjNL"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd # To handle the data set.\n",
        "import seaborn as sb # To display visualizations.\n",
        "import matplotlib.pyplot as plt # To plot\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split # To split data\n",
        "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
        "from sklearn.metrics import confusion_matrix # To calculate the confusion matrix\n",
        "from sklearn.metrics import accuracy_score # To calculate the score\n",
        "from sklearn.feature_selection import SelectKBest # Univariate Feature Selection\n",
        "from sklearn.feature_selection import chi2 # To apply Univariate Feature Selection\n",
        "from sklearn.feature_selection import RFE # Recursive Feature Selection\n",
        "from sklearn.feature_selection import RFECV # Recursive Feature Selection with Cross Validation\n",
        "from sklearn.decomposition import PCA # To apply PCA\n",
        "from sklearn import preprocessing # To get MinMax Scaler function\n",
        "\n",
        "# To plot inline\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THteAi4lH-7P"
      },
      "source": [
        "## Loading and Preparing DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jePTlir3H2aH"
      },
      "source": [
        "# Loading file and dropping some columns \n",
        "australia = pd.read_csv('weatherAUS.csv') \n",
        "australia = australia.drop(['Location','Date','Evaporation','Sunshine', 'Cloud9am','Cloud3pm',\n",
        "                           'WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am',\n",
        "                           'WindSpeed3pm'], axis=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq8Td1xBODaN"
      },
      "source": [
        "# Splitting between X and Y vector wich means the corpus and target vector respectively\n",
        "Y = australia.RainTomorrow\n",
        "X = australia.drop(['RainTomorrow'], axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4TzRYZWPwn_"
      },
      "source": [
        "''' Todo: Switch 'Yes' and 'No' with a boolen value and handle NaN values by replacing it with a zero '''\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K798SIJkQYER"
      },
      "source": [
        "## Scaling Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oMjeMAmwPM"
      },
      "source": [
        "Working with values in a wide range is not convenient, we need to scale it. In this case we are going to normalize it and scaling it in a 0-1 range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu9f_9-MQDAi"
      },
      "source": [
        "''' Todo: Scaling dataset keeping the columns name (Hint: use MinMaxScaler function).\n",
        "    Name the scaled datafarame to X_scaled'''\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etc3LKG4QrQn"
      },
      "source": [
        "## Splitting up Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65msFcKTQdvt"
      },
      "source": [
        "# Splitting  up data, seting 75% for train and 25% for test. (you can change this setup)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.25, random_state=43)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlek318yQyS-"
      },
      "source": [
        "# 1) Univariate Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht2zHzTXnDoj"
      },
      "source": [
        "This method works by selection the K best features according to a score. The K number of features is setting explicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7EZEcDVQuoj"
      },
      "source": [
        "''' Todo: Initialize SelectKBest function and create a dict to \n",
        "    visualize which features were selected with the highest score'''\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_1W4b0Knrjl"
      },
      "source": [
        "''' Todo: Print the top 5 best features '''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM2Aj9jURmfS"
      },
      "source": [
        "## Extracting the best K values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0HzDZtJn1_3"
      },
      "source": [
        "Now that we have the best features, let's extract them from the original data set and let's measure the performance with the random forest algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVbzHnwORWwV"
      },
      "source": [
        "# Using the 'UnivariateFeatureSelection' based on 'SelectKBest' function,\n",
        "# let's extract the best features from the original dataset\n",
        "\n",
        "x_train_k_best = UnivariateFeatureSelection.transform(x_train)\n",
        "x_test_k_best = UnivariateFeatureSelection.transform(x_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AQUU5xRRpYS"
      },
      "source": [
        "print(\"Shape of original data: \", x_train.shape)\n",
        "print(\"Shape of corpus with best features: \", x_train_k_best.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_YNWpcSdi7"
      },
      "source": [
        "## Testing with Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8Y02AshRrQ0"
      },
      "source": [
        "''' Todo: Initialize and fit data to the random forest classifier'''\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4rigsivSgad"
      },
      "source": [
        "''' Todo: Make a prediction and calculting the accuracy'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPaZDjB3SkH7"
      },
      "source": [
        "''' Todo: Show performance with a confusion matrix'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTtkKGOSvwc"
      },
      "source": [
        "# 2) Recursive Feature Elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y32fa3IeSpBb"
      },
      "source": [
        "# Initializing Random Forest Classifier\n",
        "RandForest_RFE = RandomForestClassifier() \n",
        "# Initializing the RFE object, one of the most important arguments is the estimator, in this case is RandomForest\n",
        "rfe = RFE(estimator=RandForest_RFE, n_features_to_select=5, step=1)\n",
        "# Fit the origial dataset\n",
        "rfe = rfe.fit(x_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GttKS3sXSywg"
      },
      "source": [
        "print(\"Best features chosen by RFE: \\n\")\n",
        "for i in x_train.columns[rfe.support_]:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5t6dV_LTKf9"
      },
      "source": [
        "## Testing with Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_qExzFqS1_Y"
      },
      "source": [
        "# Generating x_train and x_test based on the best features given by RFE\n",
        "x_train_RFE = rfe.transform(x_train)\n",
        "x_test_RFE = rfe.transform(x_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2qhhBhwTQTD"
      },
      "source": [
        "''' Todo: Fit the Random Forest'''\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Fv1uDeTVpk"
      },
      "source": [
        "''' Todo: Make a prediction and calculate the accuracy'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15piM4iRTXiM"
      },
      "source": [
        "''' Todo: Show performance with a confusion matrix'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkzXdrDWUHVq"
      },
      "source": [
        "# 3) Recursive Feature Elimination with Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU4VCMg5w3t5"
      },
      "source": [
        "This method is an extention of Recursive Feature Elimination showed above. In this method we have to set the number of k-fold cross validation, basically takes the subset of the traing set and measure the performance recurively with respect to the number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1sxaiGwTclM"
      },
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "RandForest_RFECV = RandomForestClassifier() \n",
        "''' Todo: Initialize the RFECV function setting 3-fold cross validation'''\n",
        "\n",
        "''' Todo: Fit data'''\n",
        "\n",
        "\n",
        "''' Todo: print best features'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_N5ECKqUMOK"
      },
      "source": [
        "''' Todo: Plot the best features with respect to the Cross Validation Score'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWDY2kISWoy2"
      },
      "source": [
        "# 4) Tree based Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdOjrt0Nxdx8"
      },
      "source": [
        "This method is to compute the relevance of each feature in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1o_RjJBWKlJ"
      },
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "RandForest_Tree = RandomForestClassifier()  \n",
        "# Fit the random forest with the original data\n",
        "RandForest_Tree = RandForest_Tree.fit(x_train, y_train)\n",
        "# Getting the relevance between features\n",
        "relevants = RandForest_Tree.feature_importances_"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umy0I2cdWrdy"
      },
      "source": [
        "# Apply the tree based on importance for the random forest classifier and indexing it\n",
        "std = np.std([tree.feature_importances_ for tree in RandForest_Tree.estimators_], axis=0)\n",
        "indices = np.argsort(relevants)[::-1]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe72zGz5Wtvf"
      },
      "source": [
        "''' Todo: Print the ranking of importance of each feature'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6_b48GWvu5"
      },
      "source": [
        "''' Todo: Plot the feature importances'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4H5n_mOW1gi"
      },
      "source": [
        "# 5) Feature Extraction through PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKIxUfXxrlM"
      },
      "source": [
        "In some cases it is convenient to apply dimensionality reduction to visualize the number of components or elements which could be the best for our model. In this case we apply PCA to discover which ones are the features to obtain a acceptable performance in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQor4R8_Wy5n"
      },
      "source": [
        "# Initializing PCA and fitting\n",
        "pca = PCA()\n",
        "pca.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBf7kTwW4AW"
      },
      "source": [
        "''' Plot the Variance Ratio(y label) and Number of Features(x label)'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-6speh3W8qL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}